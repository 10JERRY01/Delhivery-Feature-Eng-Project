{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "soldE3fz1y2Z"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('delhivery_data.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "    print(\"Shape of the dataset:\", df.shape)\n",
        "    print(\"\\nFirst 5 rows:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nData Info:\")\n",
        "    df.info()\n",
        "    print(\"\\nMissing values before handling:\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\nStatistical Summary:\")\n",
        "    print(df.describe(include='all'))\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'delhivery_data.csv' not found in the current directory.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3CDlu8FE1j2Q",
        "outputId": "150e1961-d459-4f03-b397-3167386c9ca8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "Shape of the dataset: (144867, 24)\n",
            "\n",
            "First 5 rows:\n",
            "       data          trip_creation_time  \\\n",
            "0  training  2018-09-20 02:35:36.476840   \n",
            "1  training  2018-09-20 02:35:36.476840   \n",
            "2  training  2018-09-20 02:35:36.476840   \n",
            "3  training  2018-09-20 02:35:36.476840   \n",
            "4  training  2018-09-20 02:35:36.476840   \n",
            "\n",
            "                                 route_schedule_uuid route_type  \\\n",
            "0  thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
            "1  thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
            "2  thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
            "3  thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
            "4  thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
            "\n",
            "                 trip_uuid source_center                 source_name  \\\n",
            "0  trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
            "1  trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
            "2  trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
            "3  trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
            "4  trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
            "\n",
            "  destination_center               destination_name  \\\n",
            "0       IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
            "1       IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
            "2       IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
            "3       IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
            "4       IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
            "\n",
            "                od_start_time  ...            cutoff_timestamp  \\\n",
            "0  2018-09-20 03:21:32.418600  ...         2018-09-20 04:27:55   \n",
            "1  2018-09-20 03:21:32.418600  ...         2018-09-20 04:17:55   \n",
            "2  2018-09-20 03:21:32.418600  ...  2018-09-20 04:01:19.505586   \n",
            "3  2018-09-20 03:21:32.418600  ...         2018-09-20 03:39:57   \n",
            "4  2018-09-20 03:21:32.418600  ...         2018-09-20 03:33:55   \n",
            "\n",
            "   actual_distance_to_destination  actual_time  osrm_time osrm_distance  \\\n",
            "0                       10.435660         14.0       11.0       11.9653   \n",
            "1                       18.936842         24.0       20.0       21.7243   \n",
            "2                       27.637279         40.0       28.0       32.5395   \n",
            "3                       36.118028         62.0       40.0       45.5620   \n",
            "4                       39.386040         68.0       44.0       54.2181   \n",
            "\n",
            "     factor  segment_actual_time  segment_osrm_time  segment_osrm_distance  \\\n",
            "0  1.272727                 14.0               11.0                11.9653   \n",
            "1  1.200000                 10.0                9.0                 9.7590   \n",
            "2  1.428571                 16.0                7.0                10.8152   \n",
            "3  1.550000                 21.0               12.0                13.0224   \n",
            "4  1.545455                  6.0                5.0                 3.9153   \n",
            "\n",
            "   segment_factor  \n",
            "0        1.272727  \n",
            "1        1.111111  \n",
            "2        2.285714  \n",
            "3        1.750000  \n",
            "4        1.200000  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 144867 entries, 0 to 144866\n",
            "Data columns (total 24 columns):\n",
            " #   Column                          Non-Null Count   Dtype  \n",
            "---  ------                          --------------   -----  \n",
            " 0   data                            144867 non-null  object \n",
            " 1   trip_creation_time              144867 non-null  object \n",
            " 2   route_schedule_uuid             144867 non-null  object \n",
            " 3   route_type                      144867 non-null  object \n",
            " 4   trip_uuid                       144867 non-null  object \n",
            " 5   source_center                   144867 non-null  object \n",
            " 6   source_name                     144574 non-null  object \n",
            " 7   destination_center              144867 non-null  object \n",
            " 8   destination_name                144606 non-null  object \n",
            " 9   od_start_time                   144867 non-null  object \n",
            " 10  od_end_time                     144867 non-null  object \n",
            " 11  start_scan_to_end_scan          144867 non-null  float64\n",
            " 12  is_cutoff                       144867 non-null  bool   \n",
            " 13  cutoff_factor                   144867 non-null  int64  \n",
            " 14  cutoff_timestamp                144867 non-null  object \n",
            " 15  actual_distance_to_destination  144867 non-null  float64\n",
            " 16  actual_time                     144867 non-null  float64\n",
            " 17  osrm_time                       144867 non-null  float64\n",
            " 18  osrm_distance                   144867 non-null  float64\n",
            " 19  factor                          144867 non-null  float64\n",
            " 20  segment_actual_time             144867 non-null  float64\n",
            " 21  segment_osrm_time               144867 non-null  float64\n",
            " 22  segment_osrm_distance           144867 non-null  float64\n",
            " 23  segment_factor                  144867 non-null  float64\n",
            "dtypes: bool(1), float64(10), int64(1), object(12)\n",
            "memory usage: 25.6+ MB\n",
            "\n",
            "Missing values before handling:\n",
            "data                                0\n",
            "trip_creation_time                  0\n",
            "route_schedule_uuid                 0\n",
            "route_type                          0\n",
            "trip_uuid                           0\n",
            "source_center                       0\n",
            "source_name                       293\n",
            "destination_center                  0\n",
            "destination_name                  261\n",
            "od_start_time                       0\n",
            "od_end_time                         0\n",
            "start_scan_to_end_scan              0\n",
            "is_cutoff                           0\n",
            "cutoff_factor                       0\n",
            "cutoff_timestamp                    0\n",
            "actual_distance_to_destination      0\n",
            "actual_time                         0\n",
            "osrm_time                           0\n",
            "osrm_distance                       0\n",
            "factor                              0\n",
            "segment_actual_time                 0\n",
            "segment_osrm_time                   0\n",
            "segment_osrm_distance               0\n",
            "segment_factor                      0\n",
            "dtype: int64\n",
            "\n",
            "Statistical Summary:\n",
            "            data          trip_creation_time  \\\n",
            "count     144867                      144867   \n",
            "unique         2                       14817   \n",
            "top     training  2018-09-22 04:55:04.835022   \n",
            "freq      104858                         101   \n",
            "mean         NaN                         NaN   \n",
            "std          NaN                         NaN   \n",
            "min          NaN                         NaN   \n",
            "25%          NaN                         NaN   \n",
            "50%          NaN                         NaN   \n",
            "75%          NaN                         NaN   \n",
            "max          NaN                         NaN   \n",
            "\n",
            "                                      route_schedule_uuid route_type  \\\n",
            "count                                              144867     144867   \n",
            "unique                                               1504          2   \n",
            "top     thanos::sroute:4029a8a2-6c74-4b7e-a6d8-f9e069f...        FTL   \n",
            "freq                                                 1812      99660   \n",
            "mean                                                  NaN        NaN   \n",
            "std                                                   NaN        NaN   \n",
            "min                                                   NaN        NaN   \n",
            "25%                                                   NaN        NaN   \n",
            "50%                                                   NaN        NaN   \n",
            "75%                                                   NaN        NaN   \n",
            "max                                                   NaN        NaN   \n",
            "\n",
            "                      trip_uuid source_center                    source_name  \\\n",
            "count                    144867        144867                         144574   \n",
            "unique                    14817          1508                           1498   \n",
            "top     trip-153759210483476123  IND000000ACB  Gurgaon_Bilaspur_HB (Haryana)   \n",
            "freq                        101         23347                          23347   \n",
            "mean                        NaN           NaN                            NaN   \n",
            "std                         NaN           NaN                            NaN   \n",
            "min                         NaN           NaN                            NaN   \n",
            "25%                         NaN           NaN                            NaN   \n",
            "50%                         NaN           NaN                            NaN   \n",
            "75%                         NaN           NaN                            NaN   \n",
            "max                         NaN           NaN                            NaN   \n",
            "\n",
            "       destination_center               destination_name  \\\n",
            "count              144867                         144606   \n",
            "unique               1481                           1468   \n",
            "top          IND000000ACB  Gurgaon_Bilaspur_HB (Haryana)   \n",
            "freq                15192                          15192   \n",
            "mean                  NaN                            NaN   \n",
            "std                   NaN                            NaN   \n",
            "min                   NaN                            NaN   \n",
            "25%                   NaN                            NaN   \n",
            "50%                   NaN                            NaN   \n",
            "75%                   NaN                            NaN   \n",
            "max                   NaN                            NaN   \n",
            "\n",
            "                     od_start_time  ...     cutoff_timestamp  \\\n",
            "count                       144867  ...               144867   \n",
            "unique                       26369  ...                93180   \n",
            "top     2018-09-21 18:37:09.322207  ...  2018-09-24 05:19:20   \n",
            "freq                            81  ...                   40   \n",
            "mean                           NaN  ...                  NaN   \n",
            "std                            NaN  ...                  NaN   \n",
            "min                            NaN  ...                  NaN   \n",
            "25%                            NaN  ...                  NaN   \n",
            "50%                            NaN  ...                  NaN   \n",
            "75%                            NaN  ...                  NaN   \n",
            "max                            NaN  ...                  NaN   \n",
            "\n",
            "        actual_distance_to_destination    actual_time      osrm_time  \\\n",
            "count                    144867.000000  144867.000000  144867.000000   \n",
            "unique                             NaN            NaN            NaN   \n",
            "top                                NaN            NaN            NaN   \n",
            "freq                               NaN            NaN            NaN   \n",
            "mean                        234.073372     416.927527     213.868272   \n",
            "std                         344.990009     598.103621     308.011085   \n",
            "min                           9.000045       9.000000       6.000000   \n",
            "25%                          23.355874      51.000000      27.000000   \n",
            "50%                          66.126571     132.000000      64.000000   \n",
            "75%                         286.708875     513.000000     257.000000   \n",
            "max                        1927.447705    4532.000000    1686.000000   \n",
            "\n",
            "        osrm_distance         factor  segment_actual_time  segment_osrm_time  \\\n",
            "count   144867.000000  144867.000000        144867.000000      144867.000000   \n",
            "unique            NaN            NaN                  NaN                NaN   \n",
            "top               NaN            NaN                  NaN                NaN   \n",
            "freq              NaN            NaN                  NaN                NaN   \n",
            "mean       284.771297       2.120107            36.196111          18.507548   \n",
            "std        421.119294       1.715421            53.571158          14.775960   \n",
            "min          9.008200       0.144000          -244.000000           0.000000   \n",
            "25%         29.914700       1.604264            20.000000          11.000000   \n",
            "50%         78.525800       1.857143            29.000000          17.000000   \n",
            "75%        343.193250       2.213483            40.000000          22.000000   \n",
            "max       2326.199100      77.387097          3051.000000        1611.000000   \n",
            "\n",
            "        segment_osrm_distance  segment_factor  \n",
            "count            144867.00000   144867.000000  \n",
            "unique                    NaN             NaN  \n",
            "top                       NaN             NaN  \n",
            "freq                      NaN             NaN  \n",
            "mean                 22.82902        2.218368  \n",
            "std                  17.86066        4.847530  \n",
            "min                   0.00000      -23.444444  \n",
            "25%                  12.07010        1.347826  \n",
            "50%                  23.51300        1.684211  \n",
            "75%                  27.81325        2.250000  \n",
            "max                2191.40370      574.250000  \n",
            "\n",
            "[11 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Basic Data Cleaning and Exploration ---\n",
        "\n",
        "# 1. Handle Missing Values\n",
        "# Strategy: Fill numerical NaNs with median/mean, categorical with mode or 'Unknown'.\n",
        "# Let's examine the columns with missing values again.\n",
        "# source_name, destination_name, od_start_time, od_end_time have few missing values.\n",
        "# segment_actual_time, segment_osrm_time, segment_osrm_distance, segment_factor have many.\n",
        "# is_cutoff, cutoff_factor, cutoff_timestamp have almost all missing - likely drop these.\n",
        "# factor also has many missing values.\n",
        "\n",
        "print(\"\\nHandling Missing Values...\")\n",
        "\n",
        "# Drop columns with too many missing values\n",
        "cols_to_drop = ['is_cutoff', 'cutoff_factor', 'cutoff_timestamp', 'factor', 'segment_factor']\n",
        "df.drop(columns=cols_to_drop, inplace=True)\n",
        "print(f\"Dropped columns: {cols_to_drop}\")\n",
        "\n",
        "# Fill missing categorical names with 'Unknown'\n",
        "df['source_name'].fillna('Unknown', inplace=True)\n",
        "df['destination_name'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Convert timestamp columns to datetime objects, coercing errors\n",
        "time_cols = ['trip_creation_time', 'od_start_time', 'od_end_time']\n",
        "for col in time_cols:\n",
        "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "# Check for NaT values introduced by coercion\n",
        "print(\"\\nNaT values after datetime conversion:\")\n",
        "print(df[time_cols].isnull().sum())\n",
        "\n",
        "# Fill missing timestamps - this is tricky. Filling with mean/median doesn't make sense.\n",
        "# Let's drop rows where od_start_time or od_end_time is missing, as they are crucial for time calculations.\n",
        "df.dropna(subset=['od_start_time', 'od_end_time'], inplace=True)\n",
        "print(f\"Dropped rows with missing od_start_time or od_end_time. New shape: {df.shape}\")\n",
        "\n",
        "# Fill missing numerical segment times/distances. Median might be better due to potential outliers.\n",
        "num_segment_cols = ['segment_actual_time', 'segment_osrm_time', 'segment_osrm_distance']\n",
        "for col in num_segment_cols:\n",
        "    median_val = df[col].median()\n",
        "    df[col].fillna(median_val, inplace=True)\n",
        "    print(f\"Filled missing values in '{col}' with median: {median_val}\")\n",
        "\n",
        "print(\"\\nMissing values after handling:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hFMhy6Rg2PwD",
        "outputId": "2f415121-7824-4aa3-cabb-646a64e43015"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Handling Missing Values...\n",
            "Dropped columns: ['is_cutoff', 'cutoff_factor', 'cutoff_timestamp', 'factor', 'segment_factor']\n",
            "\n",
            "NaT values after datetime conversion:\n",
            "trip_creation_time    0\n",
            "od_start_time         0\n",
            "od_end_time           0\n",
            "dtype: int64\n",
            "Dropped rows with missing od_start_time or od_end_time. New shape: (144867, 19)\n",
            "Filled missing values in 'segment_actual_time' with median: 29.0\n",
            "Filled missing values in 'segment_osrm_time' with median: 17.0\n",
            "Filled missing values in 'segment_osrm_distance' with median: 23.513\n",
            "\n",
            "Missing values after handling:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-a12fb893a8e2>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['source_name'].fillna('Unknown', inplace=True)\n",
            "<ipython-input-51-a12fb893a8e2>:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['destination_name'].fillna('Unknown', inplace=True)\n",
            "<ipython-input-51-a12fb893a8e2>:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(median_val, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data                              0\n",
            "trip_creation_time                0\n",
            "route_schedule_uuid               0\n",
            "route_type                        0\n",
            "trip_uuid                         0\n",
            "source_center                     0\n",
            "source_name                       0\n",
            "destination_center                0\n",
            "destination_name                  0\n",
            "od_start_time                     0\n",
            "od_end_time                       0\n",
            "start_scan_to_end_scan            0\n",
            "actual_distance_to_destination    0\n",
            "actual_time                       0\n",
            "osrm_time                         0\n",
            "osrm_distance                     0\n",
            "segment_actual_time               0\n",
            "segment_osrm_time                 0\n",
            "segment_osrm_distance             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Feature Extraction\n",
        "\n",
        "print(\"\\nExtracting Features...\")\n",
        "\n",
        "# Destination Name: City-Place-Code (State)\n",
        "# Assuming format 'City_Suffix (State)' e.g., 'Bengaluru_DC (KA)'\n",
        "df[['destination_city', 'destination_state_code']] = df['destination_name'].str.extract(r'^([^_]+)_[^_]+\\s+\\(([^)]+)\\)') # Corrected regex\n",
        "df['destination_state_code'].fillna('Unknown', inplace=True) # Handle cases that didn't match\n",
        "df['destination_city'].fillna(df['destination_name'], inplace=True) # Use full name if pattern fails\n",
        "\n",
        "# Source Name: City-Place-Code (State)\n",
        "df[['source_city', 'source_state_code']] = df['source_name'].str.extract(r'^([^_]+)_[^_]+\\s+\\(([^)]+)\\)') # Corrected regex\n",
        "df['source_state_code'].fillna('Unknown', inplace=True) # Handle cases that didn't match\n",
        "df['source_city'].fillna(df['source_name'], inplace=True) # Use full name if pattern fails\n",
        "\n",
        "# Trip Creation Time\n",
        "df['trip_creation_year'] = df['trip_creation_time'].dt.year\n",
        "df['trip_creation_month'] = df['trip_creation_time'].dt.month\n",
        "df['trip_creation_day'] = df['trip_creation_time'].dt.day\n",
        "df['trip_creation_hour'] = df['trip_creation_time'].dt.hour\n",
        "df['trip_creation_weekday'] = df['trip_creation_time'].dt.weekday # Monday=0, Sunday=6\n",
        "\n",
        "print(\"Features extracted from names and timestamps.\")\n",
        "print(df[['source_city', 'source_state_code', 'destination_city', 'destination_state_code', 'trip_creation_year', 'trip_creation_month', 'trip_creation_day']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vzzKqMJY2d_j",
        "outputId": "3a49f9e4-4a84-4ec2-f575-68b8054a296e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting Features...\n",
            "Features extracted from names and timestamps.\n",
            "                  source_city source_state_code  \\\n",
            "0  Anand_VUNagar_DC (Gujarat)           Unknown   \n",
            "1  Anand_VUNagar_DC (Gujarat)           Unknown   \n",
            "2  Anand_VUNagar_DC (Gujarat)           Unknown   \n",
            "3  Anand_VUNagar_DC (Gujarat)           Unknown   \n",
            "4  Anand_VUNagar_DC (Gujarat)           Unknown   \n",
            "\n",
            "                destination_city destination_state_code  trip_creation_year  \\\n",
            "0  Khambhat_MotvdDPP_D (Gujarat)                Unknown                2018   \n",
            "1  Khambhat_MotvdDPP_D (Gujarat)                Unknown                2018   \n",
            "2  Khambhat_MotvdDPP_D (Gujarat)                Unknown                2018   \n",
            "3  Khambhat_MotvdDPP_D (Gujarat)                Unknown                2018   \n",
            "4  Khambhat_MotvdDPP_D (Gujarat)                Unknown                2018   \n",
            "\n",
            "   trip_creation_month  trip_creation_day  \n",
            "0                    9                 20  \n",
            "1                    9                 20  \n",
            "2                    9                 20  \n",
            "3                    9                 20  \n",
            "4                    9                 20  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-ac1a5b199970>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['destination_state_code'].fillna('Unknown', inplace=True) # Handle cases that didn't match\n",
            "<ipython-input-52-ac1a5b199970>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['destination_city'].fillna(df['destination_name'], inplace=True) # Use full name if pattern fails\n",
            "<ipython-input-52-ac1a5b199970>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['source_state_code'].fillna('Unknown', inplace=True) # Handle cases that didn't match\n",
            "<ipython-input-52-ac1a5b199970>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['source_city'].fillna(df['source_name'], inplace=True) # Use full name if pattern fails\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Row Merging/Aggregation"
      ],
      "metadata": {
        "id": "dW-j0JmU4cbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Row Merging/Aggregation ---\n",
        "\n",
        "print(\"\\nMerging Rows...\")\n",
        "\n",
        "# Define aggregations\n",
        "# Numeric: sum for times/distances that accumulate, maybe mean for others?\n",
        "# Categorical: first/last\n",
        "# Timestamps: first for start, last for end\n",
        "\n",
        "# Aggregation Level 1: trip_uuid, source_center, destination_cente\n",
        "agg_funcs_level1 = {\n",
        "    'data': 'first',\n",
        "    'route_schedule_uuid': 'first', # Assuming constant within this group\n",
        "    'route_type': 'first',\n",
        "    'trip_creation_time': 'first', # Keep first creation time for the segment\n",
        "    'source_name': 'first',\n",
        "    'destination_name': 'first',\n",
        "    'od_start_time': 'first', # Start of the first segment\n",
        "    'od_end_time': 'last',   # End of the last segment within this group\n",
        "    'start_scan_to_end_scan': 'sum', # Summing time for segments\n",
        "    'actual_distance_to_destination': 'first', # Assuming this is overall distance, keep first\n",
        "    'actual_time': 'sum',\n",
        "    'osrm_time': 'sum',\n",
        "    'osrm_distance': 'sum',\n",
        "    'segment_actual_time': 'sum',\n",
        "    'segment_osrm_time': 'sum',\n",
        "    'segment_osrm_distance': 'sum',\n",
        "    # Keep extracted features\n",
        "    'destination_city': 'first',\n",
        "    'destination_state_code': 'first',\n",
        "    'source_city': 'first',\n",
        "    'source_state_code': 'first',\n",
        "    'trip_creation_year': 'first',\n",
        "    'trip_creation_month': 'first',\n",
        "    'trip_creation_day': 'first',\n",
        "    'trip_creation_hour': 'first',\n",
        "    'trip_creation_weekday': 'first'\n",
        "}\n",
        "\n",
        "# Grouping requires handling potential non-unique indices if any were created\n",
        "df_grouped_level1 = df.groupby(['trip_uuid', 'source_center', 'destination_center'], as_index=False).agg(agg_funcs_level1) # Corrected column name\n",
        "\n",
        "print(f\"Shape after grouping by trip_uuid, source, destination: {df_grouped_level1.shape}\")\n",
        "print(df_grouped_level1.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1leTg9Ub3u21",
        "outputId": "a9df7e7b-86ac-4501-e18d-504b84e67d37"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Merging Rows...\n",
            "Shape after grouping by trip_uuid, source, destination: (26368, 28)\n",
            "                 trip_uuid source_center destination_center      data  \\\n",
            "0  trip-153671041653548748  IND209304AAA       IND000000ACB  training   \n",
            "1  trip-153671041653548748  IND462022AAA       IND209304AAA  training   \n",
            "2  trip-153671042288605164  IND561203AAB       IND562101AAA  training   \n",
            "3  trip-153671042288605164  IND572101AAA       IND561203AAB  training   \n",
            "4  trip-153671043369099517  IND000000ACB       IND160002AAC  training   \n",
            "\n",
            "                                 route_schedule_uuid route_type  \\\n",
            "0  thanos::sroute:d7c989ba-a29b-4a0b-b2f4-288cdc6...        FTL   \n",
            "1  thanos::sroute:d7c989ba-a29b-4a0b-b2f4-288cdc6...        FTL   \n",
            "2  thanos::sroute:3a1b0ab2-bb0b-4c53-8c59-eb2a2c0...    Carting   \n",
            "3  thanos::sroute:3a1b0ab2-bb0b-4c53-8c59-eb2a2c0...    Carting   \n",
            "4  thanos::sroute:de5e208e-7641-45e6-8100-4d9fb1e...        FTL   \n",
            "\n",
            "          trip_creation_time                         source_name  \\\n",
            "0 2018-09-12 00:00:16.535741  Kanpur_Central_H_6 (Uttar Pradesh)   \n",
            "1 2018-09-12 00:00:16.535741  Bhopal_Trnsport_H (Madhya Pradesh)   \n",
            "2 2018-09-12 00:00:22.886430   Doddablpur_ChikaDPP_D (Karnataka)   \n",
            "3 2018-09-12 00:00:22.886430       Tumkur_Veersagr_I (Karnataka)   \n",
            "4 2018-09-12 00:00:33.691250       Gurgaon_Bilaspur_HB (Haryana)   \n",
            "\n",
            "                     destination_name              od_start_time  ...  \\\n",
            "0       Gurgaon_Bilaspur_HB (Haryana) 2018-09-12 16:39:46.858469  ...   \n",
            "1  Kanpur_Central_H_6 (Uttar Pradesh) 2018-09-12 00:00:16.535741  ...   \n",
            "2   Chikblapur_ShntiSgr_D (Karnataka) 2018-09-12 02:03:09.655591  ...   \n",
            "3   Doddablpur_ChikaDPP_D (Karnataka) 2018-09-12 00:00:22.886430  ...   \n",
            "4      Chandigarh_Mehmdpur_H (Punjab) 2018-09-14 03:40:17.106733  ...   \n",
            "\n",
            "  segment_osrm_distance                    destination_city  \\\n",
            "0              670.6205       Gurgaon_Bilaspur_HB (Haryana)   \n",
            "1              649.8528  Kanpur_Central_H_6 (Uttar Pradesh)   \n",
            "2               28.1995   Chikblapur_ShntiSgr_D (Karnataka)   \n",
            "3               55.9899   Doddablpur_ChikaDPP_D (Karnataka)   \n",
            "4              317.7408      Chandigarh_Mehmdpur_H (Punjab)   \n",
            "\n",
            "   destination_state_code                         source_city  \\\n",
            "0                 Unknown  Kanpur_Central_H_6 (Uttar Pradesh)   \n",
            "1                 Unknown  Bhopal_Trnsport_H (Madhya Pradesh)   \n",
            "2                 Unknown   Doddablpur_ChikaDPP_D (Karnataka)   \n",
            "3                 Unknown       Tumkur_Veersagr_I (Karnataka)   \n",
            "4                 Unknown       Gurgaon_Bilaspur_HB (Haryana)   \n",
            "\n",
            "   source_state_code  trip_creation_year  trip_creation_month  \\\n",
            "0            Unknown                2018                    9   \n",
            "1            Unknown                2018                    9   \n",
            "2            Unknown                2018                    9   \n",
            "3            Unknown                2018                    9   \n",
            "4            Unknown                2018                    9   \n",
            "\n",
            "   trip_creation_day  trip_creation_hour trip_creation_weekday  \n",
            "0                 12                   0                     2  \n",
            "1                 12                   0                     2  \n",
            "2                 12                   0                     2  \n",
            "3                 12                   0                     2  \n",
            "4                 12                   0                     2  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation Level 2: trip_uuid only\n",
        "# We need to decide how to aggregate the segments for a whole trip.\n",
        "# Summing times/distances makes sense. For start/end times, take the overall min/max.\n",
        "# For source/destination, take the first source and last destination?\n",
        "\n",
        "# To get the overall start/end times and first/last locations correctly, sort by time first\n",
        "df_sorted = df.sort_values(by=['trip_uuid', 'od_start_time'])\n",
        "\n",
        "agg_funcs_level2 = {\n",
        "    'data': 'first',\n",
        "    'route_schedule_uuid': 'first', # Assuming constant for the trip\n",
        "    'route_type': 'first', # Assuming constant for the trip\n",
        "    'trip_creation_time': 'first', # First creation time for the trip\n",
        "    'source_center': 'first', # First source center of the trip\n",
        "    'source_name': 'first', # First source name\n",
        "    'destination_center': 'last', # Last destination center - Corrected column name\n",
        "    'destination_name': 'last', # Last destination name\n",
        "    'od_start_time': 'min', # Earliest start time\n",
        "    'od_end_time': 'max',   # Latest end time\n",
        "    'start_scan_to_end_scan': 'sum', # Total scan-to-scan time\n",
        "    'actual_distance_to_destination': 'first', # Keep the first recorded distance? Or last? Or mean? Let's take first for now.\n",
        "    'actual_time': 'sum', # Total actual time\n",
        "    'osrm_time': 'sum', # Total OSRM time\n",
        "    'osrm_distance': 'sum', # Total OSRM distance\n",
        "    'segment_actual_time': 'sum', # Sum of segment actual times\n",
        "    'segment_osrm_time': 'sum', # Sum of segment OSRM times\n",
        "    'segment_osrm_distance': 'sum', # Sum of segment OSRM distances\n",
        "    # Keep extracted features (first/last as appropriate)\n",
        "    'destination_city': 'last',\n",
        "    'destination_state_code': 'last',\n",
        "    'source_city': 'first',\n",
        "    'source_state_code': 'first',\n",
        "    'trip_creation_year': 'first',\n",
        "    'trip_creation_month': 'first',\n",
        "    'trip_creation_day': 'first',\n",
        "    'trip_creation_hour': 'first',\n",
        "    'trip_creation_weekday': 'first'\n",
        "}\n",
        "\n",
        "df_agg_trip = df_sorted.groupby('trip_uuid', as_index=False).agg(agg_funcs_level2)\n",
        "\n",
        "print(f\"\\nShape after aggregating by trip_uuid: {df_agg_trip.shape}\")\n",
        "print(df_agg_trip.head())\n",
        "print(\"\\nAggregated Data Info:\")\n",
        "df_agg_trip.info()\n",
        "print(\"\\nAggregated Data Missing Values:\")\n",
        "print(df_agg_trip.isnull().sum()) # Check if aggregation introduced NaNs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7ALgQTLi4myT",
        "outputId": "cbd940b1-ed16-4709-993e-ab7bfc908aae"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape after aggregating by trip_uuid: (14817, 28)\n",
            "                 trip_uuid      data  \\\n",
            "0  trip-153671041653548748  training   \n",
            "1  trip-153671042288605164  training   \n",
            "2  trip-153671043369099517  training   \n",
            "3  trip-153671046011330457  training   \n",
            "4  trip-153671052974046625  training   \n",
            "\n",
            "                                 route_schedule_uuid route_type  \\\n",
            "0  thanos::sroute:d7c989ba-a29b-4a0b-b2f4-288cdc6...        FTL   \n",
            "1  thanos::sroute:3a1b0ab2-bb0b-4c53-8c59-eb2a2c0...    Carting   \n",
            "2  thanos::sroute:de5e208e-7641-45e6-8100-4d9fb1e...        FTL   \n",
            "3  thanos::sroute:f0176492-a679-4597-8332-bbd1c7f...    Carting   \n",
            "4  thanos::sroute:d9f07b12-65e0-4f3b-bec8-df06134...        FTL   \n",
            "\n",
            "          trip_creation_time source_center  \\\n",
            "0 2018-09-12 00:00:16.535741  IND462022AAA   \n",
            "1 2018-09-12 00:00:22.886430  IND572101AAA   \n",
            "2 2018-09-12 00:00:33.691250  IND562132AAA   \n",
            "3 2018-09-12 00:01:00.113710  IND400072AAB   \n",
            "4 2018-09-12 00:02:09.740725  IND583101AAA   \n",
            "\n",
            "                          source_name destination_center  \\\n",
            "0  Bhopal_Trnsport_H (Madhya Pradesh)       IND000000ACB   \n",
            "1       Tumkur_Veersagr_I (Karnataka)       IND562101AAA   \n",
            "2    Bangalore_Nelmngla_H (Karnataka)       IND160002AAC   \n",
            "3            Mumbai Hub (Maharashtra)       IND401104AAA   \n",
            "4              Bellary_Dc (Karnataka)       IND583101AAA   \n",
            "\n",
            "                    destination_name              od_start_time  ...  \\\n",
            "0      Gurgaon_Bilaspur_HB (Haryana) 2018-09-12 00:00:16.535741  ...   \n",
            "1  Chikblapur_ShntiSgr_D (Karnataka) 2018-09-12 00:00:22.886430  ...   \n",
            "2     Chandigarh_Mehmdpur_H (Punjab) 2018-09-12 00:00:33.691250  ...   \n",
            "3     Mumbai_MiraRd_IP (Maharashtra) 2018-09-12 00:01:00.113710  ...   \n",
            "4             Bellary_Dc (Karnataka) 2018-09-12 00:02:09.740725  ...   \n",
            "\n",
            "  segment_osrm_distance                   destination_city  \\\n",
            "0             1320.4733      Gurgaon_Bilaspur_HB (Haryana)   \n",
            "1               84.1894  Chikblapur_ShntiSgr_D (Karnataka)   \n",
            "2             2545.2678     Chandigarh_Mehmdpur_H (Punjab)   \n",
            "3               19.8766     Mumbai_MiraRd_IP (Maharashtra)   \n",
            "4              146.7919                            Bellary   \n",
            "\n",
            "   destination_state_code                         source_city  \\\n",
            "0                 Unknown  Bhopal_Trnsport_H (Madhya Pradesh)   \n",
            "1                 Unknown       Tumkur_Veersagr_I (Karnataka)   \n",
            "2                 Unknown    Bangalore_Nelmngla_H (Karnataka)   \n",
            "3                 Unknown            Mumbai Hub (Maharashtra)   \n",
            "4               Karnataka                             Bellary   \n",
            "\n",
            "   source_state_code  trip_creation_year  trip_creation_month  \\\n",
            "0            Unknown                2018                    9   \n",
            "1            Unknown                2018                    9   \n",
            "2            Unknown                2018                    9   \n",
            "3            Unknown                2018                    9   \n",
            "4          Karnataka                2018                    9   \n",
            "\n",
            "   trip_creation_day  trip_creation_hour trip_creation_weekday  \n",
            "0                 12                   0                     2  \n",
            "1                 12                   0                     2  \n",
            "2                 12                   0                     2  \n",
            "3                 12                   0                     2  \n",
            "4                 12                   0                     2  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "\n",
            "Aggregated Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14817 entries, 0 to 14816\n",
            "Data columns (total 28 columns):\n",
            " #   Column                          Non-Null Count  Dtype         \n",
            "---  ------                          --------------  -----         \n",
            " 0   trip_uuid                       14817 non-null  object        \n",
            " 1   data                            14817 non-null  object        \n",
            " 2   route_schedule_uuid             14817 non-null  object        \n",
            " 3   route_type                      14817 non-null  object        \n",
            " 4   trip_creation_time              14817 non-null  datetime64[ns]\n",
            " 5   source_center                   14817 non-null  object        \n",
            " 6   source_name                     14817 non-null  object        \n",
            " 7   destination_center              14817 non-null  object        \n",
            " 8   destination_name                14817 non-null  object        \n",
            " 9   od_start_time                   14817 non-null  datetime64[ns]\n",
            " 10  od_end_time                     14817 non-null  datetime64[ns]\n",
            " 11  start_scan_to_end_scan          14817 non-null  float64       \n",
            " 12  actual_distance_to_destination  14817 non-null  float64       \n",
            " 13  actual_time                     14817 non-null  float64       \n",
            " 14  osrm_time                       14817 non-null  float64       \n",
            " 15  osrm_distance                   14817 non-null  float64       \n",
            " 16  segment_actual_time             14817 non-null  float64       \n",
            " 17  segment_osrm_time               14817 non-null  float64       \n",
            " 18  segment_osrm_distance           14817 non-null  float64       \n",
            " 19  destination_city                14817 non-null  object        \n",
            " 20  destination_state_code          14817 non-null  object        \n",
            " 21  source_city                     14817 non-null  object        \n",
            " 22  source_state_code               14817 non-null  object        \n",
            " 23  trip_creation_year              14817 non-null  int32         \n",
            " 24  trip_creation_month             14817 non-null  int32         \n",
            " 25  trip_creation_day               14817 non-null  int32         \n",
            " 26  trip_creation_hour              14817 non-null  int32         \n",
            " 27  trip_creation_weekday           14817 non-null  int32         \n",
            "dtypes: datetime64[ns](3), float64(8), int32(5), object(12)\n",
            "memory usage: 2.9+ MB\n",
            "\n",
            "Aggregated Data Missing Values:\n",
            "trip_uuid                         0\n",
            "data                              0\n",
            "route_schedule_uuid               0\n",
            "route_type                        0\n",
            "trip_creation_time                0\n",
            "source_center                     0\n",
            "source_name                       0\n",
            "destination_center                0\n",
            "destination_name                  0\n",
            "od_start_time                     0\n",
            "od_end_time                       0\n",
            "start_scan_to_end_scan            0\n",
            "actual_distance_to_destination    0\n",
            "actual_time                       0\n",
            "osrm_time                         0\n",
            "osrm_distance                     0\n",
            "segment_actual_time               0\n",
            "segment_osrm_time                 0\n",
            "segment_osrm_distance             0\n",
            "destination_city                  0\n",
            "destination_state_code            0\n",
            "source_city                       0\n",
            "source_state_code                 0\n",
            "trip_creation_year                0\n",
            "trip_creation_month               0\n",
            "trip_creation_day                 0\n",
            "trip_creation_hour                0\n",
            "trip_creation_weekday             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- In-depth Analysis and Feature Engineering (on df_agg_trip) ---\n",
        "\n",
        "print(\"\\nPerforming In-depth Analysis...\")\n",
        "\n",
        "# a. Calculate time taken between od_start_time and od_end_time\n",
        "# Ensure columns are datetime\n",
        "df_agg_trip['od_start_time'] = pd.to_datetime(df_agg_trip['od_start_time'])\n",
        "df_agg_trip['od_end_time'] = pd.to_datetime(df_agg_trip['od_end_time'])\n",
        "\n",
        "# Calculate difference in hours\n",
        "df_agg_trip['od_time_diff_hours'] = (df_agg_trip['od_end_time'] - df_agg_trip['od_start_time']).dt.total_seconds() / 3600.0\n",
        "\n",
        "# Drop original columns if required (optional for now)\n",
        "# df_agg_trip.drop(columns=['od_start_time', 'od_end_time'], inplace=True)\n",
        "\n",
        "print(\"Calculated 'od_time_diff_hours'.\")\n",
        "print(df_agg_trip[['od_start_time', 'od_end_time', 'od_time_diff_hours']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IxnmFEXp4pZW",
        "outputId": "d776c054-6f0b-444b-b1ad-f39b59536eea"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing In-depth Analysis...\n",
            "Calculated 'od_time_diff_hours'.\n",
            "               od_start_time                od_end_time  od_time_diff_hours\n",
            "0 2018-09-12 00:00:16.535741 2018-09-13 13:40:23.123744           37.668497\n",
            "1 2018-09-12 00:00:22.886430 2018-09-12 03:01:59.598855            3.026865\n",
            "2 2018-09-12 00:00:33.691250 2018-09-14 17:34:55.442454           65.572709\n",
            "3 2018-09-12 00:01:00.113710 2018-09-12 01:41:29.809822            1.674916\n",
            "4 2018-09-12 00:02:09.740725 2018-09-12 12:00:30.683231           11.972484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b. Compare od_time_diff_hours and start_scan_to_end_scan\n",
        "print(\"\\nComparing 'od_time_diff_hours' and 'start_scan_to_end_scan'...\")\n",
        "# Visual Analysis\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_agg_trip, x='od_time_diff_hours', y='start_scan_to_end_scan', alpha=0.5)\n",
        "plt.title('od_time_diff_hours vs. start_scan_to_end_scan')\n",
        "plt.xlabel('OD Start to End Time Difference (hours)')\n",
        "plt.ylabel('Sum of Scan-to-Scan Time (assumed hours)') # Clarified assumed units\n",
        "plt.grid(True)\n",
        "plt.savefig('od_diff_vs_scan_time.png')\n",
        "plt.close()\n",
        "print(\"Saved scatter plot: od_diff_vs_scan_time.png\")\n",
        "\n",
        "# Basic statistics of the difference\n",
        "df_agg_trip['scan_od_diff'] = df_agg_trip['od_time_diff_hours'] - df_agg_trip['start_scan_to_end_scan']\n",
        "print(\"Statistics for (od_time_diff_hours - start_scan_to_end_scan):\")\n",
        "print(df_agg_trip['scan_od_diff'].describe())\n",
        "# Hypothesis Testing (e.g., Paired t-test if we assume they measure the same underlying duration)\n",
        "# Note: Requires assumptions (normality of differences). Visual inspection suggests non-normality.\n",
        "# A non-parametric test like Wilcoxon signed-rank test might be more appropriate.\n",
        "try:\n",
        "    stat, p_value = stats.wilcoxon(df_agg_trip['od_time_diff_hours'], df_agg_trip['start_scan_to_end_scan'])\n",
        "    print(f\"\\nWilcoxon test between od_time_diff_hours and start_scan_to_end_scan:\")\n",
        "    print(f\"Statistic: {stat}, p-value: {p_value}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"Significant difference detected (p < 0.05).\")\n",
        "    else:\n",
        "        print(\"No significant difference detected (p >= 0.05).\")\n",
        "except ValueError as e:\n",
        "    print(f\"\\nCould not perform Wilcoxon test: {e}\") # Might happen if identical values exist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b1D3I0n-5Psw",
        "outputId": "ea1b6ef6-c608-4a65-8f27-d0bb3b60d2c9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparing 'od_time_diff_hours' and 'start_scan_to_end_scan'...\n",
            "Saved scatter plot: od_diff_vs_scan_time.png\n",
            "Statistics for (od_time_diff_hours - start_scan_to_end_scan):\n",
            "count     14817.000000\n",
            "mean      -9389.220868\n",
            "std       33692.707172\n",
            "min     -396675.684341\n",
            "25%       -2815.586670\n",
            "50%        -979.891122\n",
            "75%        -405.110514\n",
            "max         -25.558347\n",
            "Name: scan_od_diff, dtype: float64\n",
            "\n",
            "Wilcoxon test between od_time_diff_hours and start_scan_to_end_scan:\n",
            "Statistic: 0.0, p-value: 0.0\n",
            "Significant difference detected (p < 0.05).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c. Compare actual_time vs OSRM time (aggregated)\n",
        "print(\"\\nComparing aggregated 'actual_time' vs 'osrm_time'...\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_agg_trip, x='osrm_time', y='actual_time', alpha=0.5)\n",
        "plt.title('Aggregated Actual Time vs. OSRM Time')\n",
        "plt.xlabel('Aggregated OSRM Time')\n",
        "plt.ylabel('Aggregated Actual Time')\n",
        "plt.plot([0, df_agg_trip[['osrm_time', 'actual_time']].max().max()], [0, df_agg_trip[['osrm_time', 'actual_time']].max().max()], ls=\"--\", c=\".3\") # Line y=x\n",
        "plt.grid(True)\n",
        "plt.savefig('actual_vs_osrm_time.png')\n",
        "plt.close()\n",
        "print(\"Saved scatter plot: actual_vs_osrm_time.png\")\n",
        "\n",
        "try:\n",
        "    stat, p_value = stats.wilcoxon(df_agg_trip['actual_time'], df_agg_trip['osrm_time'])\n",
        "    print(f\"\\nWilcoxon test between aggregated actual_time and osrm_time:\")\n",
        "    print(f\"Statistic: {stat}, p-value: {p_value}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"Significant difference detected (p < 0.05).\")\n",
        "    else:\n",
        "        print(\"No significant difference detected (p >= 0.05).\")\n",
        "except ValueError as e:\n",
        "    print(f\"\\nCould not perform Wilcoxon test: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R16ztKmw5ZN-",
        "outputId": "f502fc72-ac7a-4264-a558-af133ad00f95"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparing aggregated 'actual_time' vs 'osrm_time'...\n",
            "Saved scatter plot: actual_vs_osrm_time.png\n",
            "\n",
            "Wilcoxon test between aggregated actual_time and osrm_time:\n",
            "Statistic: 134624.0, p-value: 0.0\n",
            "Significant difference detected (p < 0.05).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d. Compare actual_time vs segment_actual_time (aggregated)\n",
        "print(\"\\nComparing aggregated 'actual_time' vs 'segment_actual_time'...\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_agg_trip, x='segment_actual_time', y='actual_time', alpha=0.5)\n",
        "plt.title('Aggregated Actual Time vs. Aggregated Segment Actual Time')\n",
        "plt.xlabel('Aggregated Segment Actual Time')\n",
        "plt.ylabel('Aggregated Actual Time')\n",
        "plt.plot([0, df_agg_trip[['segment_actual_time', 'actual_time']].max().max()], [0, df_agg_trip[['segment_actual_time', 'actual_time']].max().max()], ls=\"--\", c=\".3\")\n",
        "plt.grid(True)\n",
        "plt.savefig('actual_vs_segment_actual_time.png')\n",
        "plt.close()\n",
        "print(\"Saved scatter plot: actual_vs_segment_actual_time.png\")\n",
        "\n",
        "try:\n",
        "    stat, p_value = stats.wilcoxon(df_agg_trip['actual_time'], df_agg_trip['segment_actual_time'])\n",
        "    print(f\"\\nWilcoxon test between aggregated actual_time and segment_actual_time:\")\n",
        "    print(f\"Statistic: {stat}, p-value: {p_value}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"Significant difference detected (p < 0.05).\")\n",
        "    else:\n",
        "        print(\"No significant difference detected (p >= 0.05).\")\n",
        "except ValueError as e:\n",
        "    print(f\"\\nCould not perform Wilcoxon test: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gs8rAaRU5fzJ",
        "outputId": "3990ff03-141a-4c15-e370-3ed4d1ab3e0a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparing aggregated 'actual_time' vs 'segment_actual_time'...\n",
            "Saved scatter plot: actual_vs_segment_actual_time.png\n",
            "\n",
            "Wilcoxon test between aggregated actual_time and segment_actual_time:\n",
            "Statistic: 0.0, p-value: 0.0\n",
            "Significant difference detected (p < 0.05).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# e. Compare osrm_distance vs segment_osrm_distance (aggregated)\n",
        "print(\"\\nComparing aggregated 'osrm_distance' vs 'segment_osrm_distance'...\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_agg_trip, x='segment_osrm_distance', y='osrm_distance', alpha=0.5)\n",
        "plt.title('Aggregated OSRM Distance vs. Aggregated Segment OSRM Distance')\n",
        "plt.xlabel('Aggregated Segment OSRM Distance')\n",
        "plt.ylabel('Aggregated OSRM Distance')\n",
        "plt.plot([0, df_agg_trip[['segment_osrm_distance', 'osrm_distance']].max().max()], [0, df_agg_trip[['segment_osrm_distance', 'osrm_distance']].max().max()], ls=\"--\", c=\".3\")\n",
        "plt.grid(True)\n",
        "plt.savefig('osrm_dist_vs_segment_osrm_dist.png')\n",
        "plt.close()\n",
        "print(\"Saved scatter plot: osrm_dist_vs_segment_osrm_dist.png\")\n",
        "\n",
        "try:\n",
        "    stat, p_value = stats.wilcoxon(df_agg_trip['osrm_distance'], df_agg_trip['segment_osrm_distance'])\n",
        "    print(f\"\\nWilcoxon test between aggregated osrm_distance and segment_osrm_distance:\")\n",
        "    print(f\"Statistic: {stat}, p-value: {p_value}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"Significant difference detected (p < 0.05).\")\n",
        "    else:\n",
        "        print(\"No significant difference detected (p >= 0.05).\")\n",
        "except ValueError as e:\n",
        "    print(f\"\\nCould not perform Wilcoxon test: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6ymeMk6U5jsG",
        "outputId": "13411f41-8c9b-4737-b662-8f41ddd440e4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparing aggregated 'osrm_distance' vs 'segment_osrm_distance'...\n",
            "Saved scatter plot: osrm_dist_vs_segment_osrm_dist.png\n",
            "\n",
            "Wilcoxon test between aggregated osrm_distance and segment_osrm_distance:\n",
            "Statistic: 26304.0, p-value: 0.0\n",
            "Significant difference detected (p < 0.05).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# f. Compare osrm_time vs segment_osrm_time (aggregated)\n",
        "print(\"\\nComparing aggregated 'osrm_time' vs 'segment_osrm_time'...\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_agg_trip, x='segment_osrm_time', y='osrm_time', alpha=0.5)\n",
        "plt.title('Aggregated OSRM Time vs. Aggregated Segment OSRM Time')\n",
        "plt.xlabel('Aggregated Segment OSRM Time')\n",
        "plt.ylabel('Aggregated OSRM Time')\n",
        "plt.plot([0, df_agg_trip[['segment_osrm_time', 'osrm_time']].max().max()], [0, df_agg_trip[['segment_osrm_time', 'osrm_time']].max().max()], ls=\"--\", c=\".3\")\n",
        "plt.grid(True)\n",
        "plt.savefig('osrm_time_vs_segment_osrm_time.png')\n",
        "plt.close()\n",
        "print(\"Saved scatter plot: osrm_time_vs_segment_osrm_time.png\")\n",
        "\n",
        "try:\n",
        "    stat, p_value = stats.wilcoxon(df_agg_trip['osrm_time'], df_agg_trip['segment_osrm_time'])\n",
        "    print(f\"\\nWilcoxon test between aggregated osrm_time and segment_osrm_time:\")\n",
        "    print(f\"Statistic: {stat}, p-value: {p_value}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"Significant difference detected (p < 0.05).\")\n",
        "    else:\n",
        "        print(\"No significant difference detected (p >= 0.05).\")\n",
        "except ValueError as e:\n",
        "    print(f\"\\nCould not perform Wilcoxon test: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1d0RR1y35odR",
        "outputId": "3ddcad5d-6ea8-440e-c77b-9769a3eca725"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparing aggregated 'osrm_time' vs 'segment_osrm_time'...\n",
            "Saved scatter plot: osrm_time_vs_segment_osrm_time.png\n",
            "\n",
            "Wilcoxon test between aggregated osrm_time and segment_osrm_time:\n",
            "Statistic: 21161.5, p-value: 0.0\n",
            "Significant difference detected (p < 0.05).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Outlier Detection and Treatment ---\n",
        "\n",
        "print(\"\\nHandling Outliers...\")\n",
        "\n",
        "numerical_cols = df_agg_trip.select_dtypes(include=np.number).columns.tolist()\n",
        "# Remove identifier/categorical-like numeric columns if any (e.g., year, month, day)\n",
        "cols_to_exclude_outliers = ['trip_creation_year', 'trip_creation_month', 'trip_creation_day', 'trip_creation_hour', 'trip_creation_weekday']\n",
        "numerical_cols = [col for col in numerical_cols if col not in cols_to_exclude_outliers]\n",
        "\n",
        "print(f\"Numerical columns for outlier check: {numerical_cols}\")\n",
        "\n",
        "# Visual Analysis (Boxplots)\n",
        "plt.figure(figsize=(15, len(numerical_cols) * 2))\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    plt.subplot(len(numerical_cols), 1, i + 1)\n",
        "    sns.boxplot(x=df_agg_trip[col])\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "plt.tight_layout()\n",
        "plt.savefig('boxplots_before_outlier_treatment.png')\n",
        "plt.close()\n",
        "print(\"Saved boxplots: boxplots_before_outlier_treatment.png\")\n",
        "\n",
        "# Handle outliers using IQR method\n",
        "df_cleaned = df_agg_trip.copy()\n",
        "outliers_info = {}\n",
        "\n",
        "for col in numerical_cols:\n",
        "    Q1 = df_cleaned[col].quantile(0.25)\n",
        "    Q3 = df_cleaned[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    original_count = df_cleaned.shape[0]\n",
        "    # Cap the outliers instead of removing\n",
        "    df_cleaned[col] = np.where(df_cleaned[col] < lower_bound, lower_bound, df_cleaned[col])\n",
        "    df_cleaned[col] = np.where(df_cleaned[col] > upper_bound, upper_bound, df_cleaned[col])\n",
        "\n",
        "    outliers_count = original_count - df_cleaned[(df_cleaned[col] >= lower_bound) & (df_cleaned[col] <= upper_bound)].shape[0] # Re-check count based on original bounds\n",
        "    outliers_info[col] = {'lower': lower_bound, 'upper': upper_bound, 'count_capped': outliers_count}\n",
        "    print(f\"Capped outliers in '{col}' using IQR bounds [{lower_bound:.2f}, {upper_bound:.2f}]. Approx Capped: {outliers_count}\")\n",
        "\n",
        "\n",
        "print(\"\\nOutlier capping summary:\")\n",
        "# print(outliers_info) # Can be verbose\n",
        "\n",
        "# Visual Analysis After Capping\n",
        "plt.figure(figsize=(15, len(numerical_cols) * 2))\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    plt.subplot(len(numerical_cols), 1, i + 1)\n",
        "    sns.boxplot(x=df_cleaned[col])\n",
        "    plt.title(f'Boxplot of {col} (After Capping)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('boxplots_after_outlier_treatment.png')\n",
        "plt.close()\n",
        "print(\"Saved boxplots after capping: boxplots_after_outlier_treatment.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5VIt2hg95wnF",
        "outputId": "ef56b640-e0a7-409b-9d7e-0546001dec3b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Handling Outliers...\n",
            "Numerical columns for outlier check: ['start_scan_to_end_scan', 'actual_distance_to_destination', 'actual_time', 'osrm_time', 'osrm_distance', 'segment_actual_time', 'segment_osrm_time', 'segment_osrm_distance', 'od_time_diff_hours', 'scan_od_diff']\n",
            "Saved boxplots: boxplots_before_outlier_treatment.png\n",
            "Capped outliers in 'start_scan_to_end_scan' using IQR bounds [-3219.00, 6453.00]. Approx Capped: 0\n",
            "Capped outliers in 'actual_distance_to_destination' using IQR bounds [-10.14, 42.12]. Approx Capped: 0\n",
            "Capped outliers in 'actual_time' using IQR bounds [-1239.50, 2444.50]. Approx Capped: 0\n",
            "Capped outliers in 'osrm_time' using IQR bounds [-619.00, 1197.00]. Approx Capped: 0\n",
            "Capped outliers in 'osrm_distance' using IQR bounds [-747.17, 1420.59]. Approx Capped: 0\n",
            "Capped outliers in 'segment_actual_time' using IQR bounds [-385.50, 818.50]. Approx Capped: 0\n",
            "Capped outliers in 'segment_osrm_time' using IQR bounds [-200.00, 416.00]. Approx Capped: 0\n",
            "Capped outliers in 'segment_osrm_distance' using IQR bounds [-246.57, 498.02]. Approx Capped: 0\n",
            "Capped outliers in 'od_time_diff_hours' using IQR bounds [-10.53, 24.28]. Approx Capped: 0\n",
            "Capped outliers in 'scan_od_diff' using IQR bounds [-6431.30, 3210.60]. Approx Capped: 0\n",
            "\n",
            "Outlier capping summary:\n",
            "Saved boxplots after capping: boxplots_after_outlier_treatment.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Categorical Variable Handling ---\n",
        "\n",
        "print(\"\\nHandling Categorical Variables...\")\n",
        "\n",
        "categorical_cols = df_cleaned.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "# Also include state codes which were extracted\n",
        "categorical_cols.extend(['source_state_code', 'destination_state_code'])\n",
        "# Remove high cardinality columns like names/IDs if they are still object type\n",
        "cols_to_exclude_encoding = ['trip_uuid', 'route_schedule_uuid', 'source_name', 'destination_name', 'source_city', 'destination_city']\n",
        "categorical_cols = [col for col in categorical_cols if col not in cols_to_exclude_encoding and col in df_cleaned.columns]\n",
        "\n",
        "print(f\"Categorical columns for encoding: {categorical_cols}\")\n",
        "\n",
        "# One-Hot Encoding\n",
        "df_encoded = pd.get_dummies(df_cleaned, columns=categorical_cols, drop_first=True, dummy_na=False) # drop_first to avoid multicollinearity\n",
        "\n",
        "print(f\"Shape after One-Hot Encoding: {df_encoded.shape}\")\n",
        "print(\"Columns after encoding (sample):\", df_encoded.columns[:20].tolist(), \"...\") # Show some new columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "21Hf1V2m6ARV",
        "outputId": "0788a6b6-5a62-417b-cffa-ea05dcc9cb4f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Handling Categorical Variables...\n",
            "Categorical columns for encoding: ['data', 'route_type', 'source_center', 'destination_center', 'destination_state_code', 'source_state_code', 'source_state_code', 'destination_state_code']\n",
            "Shape after One-Hot Encoding: (14817, 1924)\n",
            "Columns after encoding (sample): ['trip_uuid', 'route_schedule_uuid', 'trip_creation_time', 'source_name', 'destination_name', 'od_start_time', 'od_end_time', 'start_scan_to_end_scan', 'actual_distance_to_destination', 'actual_time', 'osrm_time', 'osrm_distance', 'segment_actual_time', 'segment_osrm_time', 'segment_osrm_distance', 'destination_city', 'source_city', 'trip_creation_year', 'trip_creation_month', 'trip_creation_day'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Normalization / Standardization ---\n",
        "\n",
        "print(\"\\nNormalizing/Standardizing Numerical Features...\")\n",
        "\n",
        "# Select numerical columns again from the encoded dataframe\n",
        "numerical_cols_encoded = df_encoded.select_dtypes(include=np.number).columns.tolist()\n",
        "# Exclude identifiers and previously excluded cols\n",
        "ids_and_time_parts = ['trip_creation_year', 'trip_creation_month', 'trip_creation_day', 'trip_creation_hour', 'trip_creation_weekday'] # Keep these as they are or treat differently if needed\n",
        "numerical_cols_to_scale = [col for col in numerical_cols_encoded if col not in ids_and_time_parts and col in numerical_cols] # Use original list to ensure we scale the right ones\n",
        "\n",
        "print(f\"Numerical columns to scale: {numerical_cols_to_scale}\")\n",
        "\n",
        "# Using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df_scaled = df_encoded.copy()\n",
        "df_scaled[numerical_cols_to_scale] = scaler.fit_transform(df_scaled[numerical_cols_to_scale])\n",
        "\n",
        "print(\"Applied StandardScaler to numerical features.\")\n",
        "print(\"\\nScaled Data Sample (first 5 rows, selected columns):\")\n",
        "print(df_scaled[numerical_cols_to_scale].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vQi2iKXU6BfC",
        "outputId": "cc3a9ae8-89ab-477c-a6ac-42865c39551d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Normalizing/Standardizing Numerical Features...\n",
            "Numerical columns to scale: ['start_scan_to_end_scan', 'actual_distance_to_destination', 'actual_time', 'osrm_time', 'osrm_distance', 'segment_actual_time', 'segment_osrm_time', 'segment_osrm_distance', 'od_time_diff_hours', 'scan_od_diff']\n",
            "Applied StandardScaler to numerical features.\n",
            "\n",
            "Scaled Data Sample (first 5 rows, selected columns):\n",
            "   start_scan_to_end_scan  actual_distance_to_destination  actual_time  \\\n",
            "0                2.054511                        1.031426     2.048605   \n",
            "1               -0.501487                       -0.802293    -0.422573   \n",
            "2                2.054511                        1.610061     2.048605   \n",
            "3               -0.826804                       -0.587269    -0.805542   \n",
            "4               -0.188150                        0.965086    -0.232900   \n",
            "\n",
            "   osrm_time  osrm_distance  segment_actual_time  segment_osrm_time  \\\n",
            "0   2.100171       2.063424             2.149256           2.256743   \n",
            "1  -0.363660      -0.309542            -0.465311          -0.475861   \n",
            "2   2.100171       2.063424             2.149256           2.256743   \n",
            "3  -0.827968      -0.799703            -0.781760          -0.857336   \n",
            "4  -0.371149      -0.316013             0.302658          -0.086601   \n",
            "\n",
            "   segment_osrm_distance  od_time_diff_hours  scan_od_diff  \n",
            "0               2.262408            2.258645     -2.054434  \n",
            "1              -0.404369           -0.673529      0.500689  \n",
            "2               2.262408            2.258645     -2.054434  \n",
            "3              -0.818804           -0.860091      0.826368  \n",
            "4              -0.000954            0.560922      0.190536  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Final Data ---\n",
        "print(\"\\nFinal processed data shape:\", df_scaled.shape)\n",
        "# Save the processed data\n",
        "df_scaled.to_csv('delhivery_data_processed.csv', index=False)\n",
        "print(\"Saved processed data to 'delhivery_data_processed.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KiGxIABT6NlJ",
        "outputId": "9b58354d-20fd-4c0b-98fc-4e90ba880aaf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final processed data shape: (14817, 1924)\n",
            "Saved processed data to 'delhivery_data_processed.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Basic Business Insights  ---\n",
        "print(\"\\n--- Basic Business Insights ---\")\n",
        "\n",
        "# 1. Most frequent routes (Source State -> Destination State)\n",
        "df_agg_trip['route'] = df_agg_trip['source_state_code'] + ' -> ' + df_agg_trip['destination_state_code']\n",
        "top_routes = df_agg_trip['route'].value_counts().head(10)\n",
        "print(\"\\nTop 10 Routes (Source State -> Destination State):\")\n",
        "print(top_routes)\n",
        "\n",
        "# 2. Busiest Corridors (Source City -> Destination City) - High Cardinality Warning\n",
        "df_agg_trip['corridor'] = df_agg_trip['source_city'] + ' -> ' + df_agg_trip['destination_city']\n",
        "top_corridors = df_agg_trip['corridor'].value_counts().head(10)\n",
        "print(\"\\nTop 10 Corridors (Source City -> Destination City):\")\n",
        "print(top_corridors)\n",
        "\n",
        "# 3. Average time/distance for top routes\n",
        "print(\"\\nAverage Metrics for Top 5 Routes:\")\n",
        "for route in top_routes.head(5).index:\n",
        "    route_data = df_agg_trip[df_agg_trip['route'] == route]\n",
        "    avg_actual_time = route_data['actual_time'].mean()\n",
        "    avg_osrm_time = route_data['osrm_time'].mean()\n",
        "    avg_osrm_dist = route_data['osrm_distance'].mean()\n",
        "    avg_od_diff = route_data['od_time_diff_hours'].mean()\n",
        "    print(f\"\\nRoute: {route}\")\n",
        "    print(f\"  Avg Actual Time: {avg_actual_time:.2f}\")\n",
        "    print(f\"  Avg OSRM Time: {avg_osrm_time:.2f}\")\n",
        "    print(f\"  Avg OSRM Distance: {avg_osrm_dist:.2f}\")\n",
        "    print(f\"  Avg Trip Duration (OD): {avg_od_diff:.2f} hours\")\n",
        "\n",
        "# 4. Distribution of Route Types\n",
        "print(\"\\nDistribution of Route Types:\")\n",
        "print(df_agg_trip['route_type'].value_counts(normalize=True) * 100)\n",
        "\n",
        "\n",
        "print(\"\\n--- End of Analysis ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Rr9rF-pZ6Sfn",
        "outputId": "306bf480-72d8-40e9-a933-78e44b38c8a5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Basic Business Insights ---\n",
            "\n",
            "Top 10 Routes (Source State -> Destination State):\n",
            "route\n",
            "Unknown -> Unknown        12978\n",
            "Tamil Nadu -> Unknown       123\n",
            "Gujarat -> Unknown          120\n",
            "Maharashtra -> Unknown      119\n",
            "Unknown -> Gujarat           99\n",
            "Unknown -> Rajasthan         86\n",
            "Jharkhand -> Unknown         71\n",
            "Rajasthan -> Unknown         68\n",
            "Punjab -> Punjab             67\n",
            "Unknown -> Haryana           67\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top 10 Corridors (Source City -> Destination City):\n",
            "corridor\n",
            "Chandigarh_Mehmdpur_H (Punjab) -> Chandigarh_Mehmdpur_H (Punjab)          175\n",
            "Bangalore_Nelmngla_H (Karnataka) -> Bengaluru_KGAirprt_HB (Karnataka)     151\n",
            "Muzaffrpur_Bbganj_I (Bihar) -> Muzaffrpur_Bbganj_I (Bihar)                130\n",
            "Bengaluru_Bomsndra_HB (Karnataka) -> Bengaluru_KGAirprt_HB (Karnataka)    121\n",
            "Bhiwandi_Mankoli_HB (Maharashtra) -> Bhiwandi_Mankoli_HB (Maharashtra)    113\n",
            "Bengaluru_KGAirprt_HB (Karnataka) -> Bangalore_Nelmngla_H (Karnataka)     108\n",
            "Ahmedabad_East_H_1 (Gujarat) -> Ahmedabad_East_H_1 (Gujarat)              107\n",
            "Bhiwandi_Mankoli_HB (Maharashtra) -> Mumbai Hub (Maharashtra)             105\n",
            "Mumbai_Chndivli_PC (Maharashtra) -> Bhiwandi_Mankoli_HB (Maharashtra)      99\n",
            "Bangalore_Nelmngla_H (Karnataka) -> Bengaluru_Bomsndra_HB (Karnataka)      97\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Average Metrics for Top 5 Routes:\n",
            "\n",
            "Route: Unknown -> Unknown\n",
            "  Avg Actual Time: 3990.09\n",
            "  Avg OSRM Time: 2075.11\n",
            "  Avg OSRM Distance: 2757.19\n",
            "  Avg Trip Duration (OD): 9.08 hours\n",
            "\n",
            "Route: Tamil Nadu -> Unknown\n",
            "  Avg Actual Time: 124.24\n",
            "  Avg OSRM Time: 57.11\n",
            "  Avg OSRM Distance: 65.09\n",
            "  Avg Trip Duration (OD): 1.68 hours\n",
            "\n",
            "Route: Gujarat -> Unknown\n",
            "  Avg Actual Time: 8323.50\n",
            "  Avg OSRM Time: 4580.62\n",
            "  Avg OSRM Distance: 6149.22\n",
            "  Avg Trip Duration (OD): 11.19 hours\n",
            "\n",
            "Route: Maharashtra -> Unknown\n",
            "  Avg Actual Time: 1560.35\n",
            "  Avg OSRM Time: 742.69\n",
            "  Avg OSRM Distance: 1033.66\n",
            "  Avg Trip Duration (OD): 5.01 hours\n",
            "\n",
            "Route: Unknown -> Gujarat\n",
            "  Avg Actual Time: 3358.87\n",
            "  Avg OSRM Time: 1830.51\n",
            "  Avg OSRM Distance: 2377.93\n",
            "  Avg Trip Duration (OD): 8.20 hours\n",
            "\n",
            "Distribution of Route Types:\n",
            "route_type\n",
            "Carting    60.120132\n",
            "FTL        39.879868\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "--- End of Analysis ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pxrQcWzS8cHw"
      },
      "execution_count": 65,
      "outputs": []
    }
  ]
}